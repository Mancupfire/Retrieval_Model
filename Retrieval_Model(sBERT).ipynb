{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mancupfire/Retrieval_Model/blob/main/Retrieval_Model(sBERT).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah9xudAIFM5r",
        "outputId": "6db73963-c985-427d-c6f0-a739c904f449"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "jWzYvYLJDy8w"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Sentence-BERT model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "K9YXRaKbDy6o"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đọc dữ liệu huấn luyện\n",
        "with open('edinburgh-keywords_train.json', 'r') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "keywords = list(train_data['np2count'].keys())"
      ],
      "metadata": {
        "id": "5axvl5OqDy4g"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loại bỏ những từ bị trùng\n",
        "keyword_set = set(keywords)"
      ],
      "metadata": {
        "id": "yL9m3MDzDy2P"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgVVx0ooIFtR",
        "outputId": "f5291eac-450f-4571-8383-f7624a2dd944"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good',\n",
              " 'chinese takeaway',\n",
              " 'ribs',\n",
              " 'great starters',\n",
              " 'mains',\n",
              " 'kung',\n",
              " 'decent portion',\n",
              " 'way',\n",
              " 'thai food',\n",
              " 'edinburgh']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_users(info):\n",
        "    l_user, user2kw = [], []\n",
        "    for ii in info:\n",
        "        lus = info[ii]\n",
        "        for u in lus:\n",
        "            if u not in l_user:\n",
        "                l_user.append(u)\n",
        "                user2kw.append([])\n",
        "            idx = l_user.index(u)\n",
        "            user2kw[idx].append(ii)\n",
        "    return l_user, user2kw"
      ],
      "metadata": {
        "id": "tph1Z16zDyz5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_users, train_users2kw = extract_users(train_data['np2users'])"
      ],
      "metadata": {
        "id": "cy__15VlD7DH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_set = set()\n",
        "listres = []\n",
        "for kw in train_data['np2rests'].keys():\n",
        "    listres.extend(train_data['np2rests'][kw].keys())\n",
        "restaurant_set = set(listres)"
      ],
      "metadata": {
        "id": "VGPMhQikD7A3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo ma trận liên kết từ keywords và restaurant\n",
        "keyword_set = list(keyword_set)\n",
        "restaurant_set = list(restaurant_set)\n",
        "restaurants = len(listres)\n",
        "num_keywords = len(keyword_set)\n",
        "num_restaurants = len(restaurant_set)\n",
        "a = np.zeros((num_keywords, num_restaurants))\n",
        "\n",
        "for kw in train_data['np2rests'].keys():\n",
        "    for res in train_data['np2rests'][kw].keys():\n",
        "        idx_kw = keyword_set.index(kw)\n",
        "        idx_res = restaurant_set.index(res)\n",
        "        a[idx_kw][idx_res] = 1"
      ],
      "metadata": {
        "id": "2YyrYz1DD6-6"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mã hóa các từ khóa trong tập huấn luyện\n",
        "keyword_embeddings = model.encode(list(keyword_set))"
      ],
      "metadata": {
        "id": "AP5PGOWdD68X"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đọc dữ liệu kiểm tra\n",
        "with open('edinburgh-keywords_test.json', 'r') as r:\n",
        "    test_data = json.load(r)\n",
        "\n",
        "user_keywords = list(test_data['np2reviews'].keys())\n",
        "user_keywords_list = list(user_keywords)"
      ],
      "metadata": {
        "id": "lWUXZioxErkR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_users, test_users2kw = extract_users(test_data['np2users'])"
      ],
      "metadata": {
        "id": "-AiNErxVErh5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mã hóa các từ khóa trong tập kiểm tra\n",
        "test_keywords = [kw for sublist in test_users2kw for kw in sublist]\n",
        "test_keyword_embeddings = model.encode(test_keywords)"
      ],
      "metadata": {
        "id": "O9U8nMwMErfh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tính toán độ tương đồng giữa từ khóa kiểm tra và từ khóa huấn luyện\n",
        "similarity_scores = cosine_similarity(test_keyword_embeddings, keyword_embeddings)\n"
      ],
      "metadata": {
        "id": "7W5sGIsnErdJ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "K2ynHQAGGaTi"
      },
      "outputs": [],
      "source": [
        "filtered_keywords = []\n",
        "for i, user_kw in enumerate(test_users2kw):\n",
        "    updated_user_kw = []\n",
        "    for kw in user_kw:\n",
        "        if kw not in keyword_set:\n",
        "            # Lấy vị trí của test keyword trong ma trận similarity_scores\n",
        "            test_idx = test_keywords.index(kw)\n",
        "            sim_scores = similarity_scores[test_idx]\n",
        "\n",
        "            # Tìm keyword trong traindata có cosine similarity lớn nhất\n",
        "            best_match_idx = np.argmax(sim_scores)\n",
        "            best_match_keyword = keyword_set[best_match_idx]\n",
        "\n",
        "            # Thay thế nhau\n",
        "            updated_user_kw.append(best_match_keyword)\n",
        "        else:\n",
        "            updated_user_kw.append(kw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cập nhật danh sách từ khóa người dùng\n",
        "filtered_keywords.append(updated_user_kw)"
      ],
      "metadata": {
        "id": "7D4J0nHzE5dl"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cập nhật lại test_users2kw sau khi thay thế\n",
        "test_users2kw = filtered_keywords"
      ],
      "metadata": {
        "id": "ZHSkFFm9E6MK"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for kw in test_users2kw:\n",
        "    t = np.zeros((1, len(keyword_set)))\n",
        "    keywords = kw[:10]\n",
        "    for keys in keywords:\n",
        "        if keys in keyword_set:\n",
        "            idx_kw = keyword_set.index(keys)\n",
        "            t[0][idx_kw] = 1\n",
        "    R = np.dot(t, a)\n",
        "    result = np.argsort(R[0])[::-1][:10]"
      ],
      "metadata": {
        "id": "wzoKm5RUE6Jr"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b4Cr4DhdHYn",
        "outputId": "d5af637c-e313-467e-fa7a-66f0458818a3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([399, 887, 208,  80, 740, 159, 564, 534, 171, 436])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_at_k(predictions, ground_truth, k):\n",
        "    \"\"\"\n",
        "    Calculate Precision@k for a single user.\n",
        "    \"\"\"\n",
        "    relevant_items = set(ground_truth)\n",
        "    top_k_predictions = set(predictions[:k])\n",
        "    return len(relevant_items.intersection(top_k_predictions)) / k\n",
        "\n",
        "def recall_at_k(predictions, ground_truth, k):\n",
        "    \"\"\"\n",
        "    Calculate Recall@k for a single user.\n",
        "    \"\"\"\n",
        "    relevant_items = set(ground_truth)\n",
        "    top_k_predictions = set(predictions[:k])\n",
        "    return len(relevant_items.intersection(top_k_predictions)) / len(relevant_items)\n",
        "\n",
        "def f1_at_k(predictions, ground_truth, k):\n",
        "    \"\"\"\n",
        "    Calculate F1@k for a single user.\n",
        "    \"\"\"\n",
        "    precision = precision_at_k(predictions, ground_truth, k)\n",
        "    recall = recall_at_k(predictions, ground_truth, k)\n",
        "    if precision + recall == 0:\n",
        "        return 0\n",
        "    return 2 * (precision * recall) / (precision + recall)"
      ],
      "metadata": {
        "id": "feVPi0g4FTRP"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 10\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for i, user_kw_list in enumerate(test_users2kw):\n",
        "    ground_truth = set()\n",
        "    for user_kw in user_kw_list:\n",
        "        ground_truth.update(test_data['np2rests'].get(user_kw, {}).keys())\n",
        "\n",
        "    if not ground_truth:\n",
        "        continue\n",
        "\n",
        "    # Generate ra top-k recommendations\n",
        "    t = np.zeros((1, len(keyword_set)))\n",
        "    keywords = user_kw_list[:10]  # Top 10 keywords cho user\n",
        "    for keys in keywords:\n",
        "        if keys in keyword_set:\n",
        "            idx_kw = keyword_set.index(keys)\n",
        "            t[0][idx_kw] = 1\n",
        "\n",
        "    R = np.dot(t, a)\n",
        "    result = np.argsort(R[0])[::-1][:k]\n",
        "\n",
        "    predicted_restaurants = [restaurant_set[idx] for idx in result]\n",
        "\n",
        "    # Evaluate metrics\n",
        "    precision_scores.append(precision_at_k(predicted_restaurants, ground_truth, k))\n",
        "    recall_scores.append(recall_at_k(predicted_restaurants, ground_truth, k))\n",
        "    f1_scores.append(f1_at_k(predicted_restaurants, ground_truth, k))\n",
        "\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Precision@{k}: {avg_precision:.4f}\")\n",
        "print(f\"Recall@{k}: {avg_recall:.4f}\")\n",
        "print(f\"F1@{k}: {avg_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_ZmELXZP7Dy",
        "outputId": "11ce3f05-9d45-447b-8736-5b7f7382a524"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@10: 0.6000\n",
            "Recall@10: 0.0228\n",
            "F1@10: 0.0440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9eIvCeiP69M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}